{
  "algorithm": "PPO",
  "environment": "Pong-v0",

  "steps": 20000,
  "memory_size": 100000,
  "network_train_frequency": 4,
  "learning_rate": 0.00025,
  "gamma": 0.99,
  "reward_clipping": false,

  "save_model": true,
  "load_model": false,
  "save_gif": false,
  "save_tensorboard_summary": false,

  "save_plot_frequency": 1000000,
  "save_model_frequency": 5000,
  "save_gif_frequency": 100000,
  "test_frequency": 10000,
  "model_file": "Pong-v0_13_2019-05-15 15:22:46.244962.h5",

  "batch_size": 32,

  "target_update_frequency": null,

  "initial_exploration_steps": null,
  "epsilon": null,
  "epsilon_min": null,
  "epsilon_explore": null,

  "clipping_loss_ratio": 0.1,
  "lambda": 0.95,
  "epochs": 3,
  "horizon": 256
}